{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import jieba #中文斷詞函式庫\n",
    "\n",
    "headers = requests.utils.default_headers()\n",
    "headers['User-Agent'] = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'\n",
    "#解決有些網站無法被爬蟲的問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/Users/richard/Documents/0Python/chromedriver')\n",
    "#載入webdriver\n",
    "\n",
    "wait = ui.WebDriverWait(driver,60)\n",
    "#載入等候時間（60秒內持續掃瞄）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '水果'\n",
    "url = 'https://find.ruten.com.tw/s/?q={}'.format(keyword) \n",
    "\n",
    "driver.get(url) #用瀏覽器開啟網頁\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser') #用bs解析網頁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_page = int(soup.find('li', class_='info').text[1:])  #用find找到頁數，用index排除數字１，找到最大頁數，再用int化為數字 #決定後續翻頁次數使用\n",
    "\n",
    "max_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameL = []\n",
    "for i in range(1, max_page+1):\n",
    "    new_url = url+'&p='+str(i) \n",
    "    driver.get(new_url) \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    original_nameL = soup.select('h5>a') #抓符合條件的關鍵字（標題）\n",
    "    for i in original_nameL:\n",
    "        name = i.get_text()\n",
    "        seg_list = jieba.lcut(name, cut_all=False) #抓出關鍵字後就先斷詞\n",
    "        nameL += seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords=[]\n",
    "remainderWords=[]\n",
    "\n",
    "with open('/Users/richard/Documents/0Python/WebCrawling/stopWords.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopWords.append(data) #建立廢詞庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainderWords = list(filter(lambda a: a not in stopWords and a != '\\n', nameL)) #用斷詞後結果與廢詞比對，留下非廢詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "\n",
    "for i in remainderWords:\n",
    "    if i.title() in dic:\n",
    "        dic[i.title()] += 1 #計算出現次數\n",
    "    else:\n",
    "        dic[i.title()] = 1\n",
    "        \n",
    "\n",
    "df = pd.DataFrame(list(dic.items()), columns=['關鍵字', '出現次數'])\n",
    "\n",
    "df_sort = df.sort_values(by=['出現次數'], ascending = False).reset_index(drop = True)\n",
    "df_sort['搜尋結果'] = 'https://find.ruten.com.tw/s/?q='+df_sort['關鍵字'] #新增搜尋結果，方便點擊連結\n",
    "df_20 = df_sort.head(20)\n",
    "df_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sort.to_excel('露天_'+keyword+'_全關鍵字.xlsx') #輸出檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
